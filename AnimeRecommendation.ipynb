{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRpgVGGhzEu8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, TextVectorization, Lambda\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t96EhwEO0_gK",
        "outputId": "9e2065ab-e7e2-4d6d-d9c5-ef9892dfc1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/animes.csv')"
      ],
      "metadata": {
        "id": "EuI4I23NzQ_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('')\n"
      ],
      "metadata": {
        "id": "Fgd9sN-B12ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_start_year(aired):\n",
        "    try:\n",
        "        if pd.isna(aired):\n",
        "            return np.nan\n",
        "        start_year = int(str(aired).split()[2])\n",
        "        return start_year\n",
        "    except (ValueError, IndexError):\n",
        "        return np.nan\n",
        "\n",
        "# Apply the function to create a new 'start_year' column\n",
        "df['start_year'] = df['aired'].apply(extract_start_year)\n",
        "\n",
        "def preprocess_aired(row):\n",
        "    aired = row['aired']\n",
        "    # Check if the value is a float or NaN\n",
        "    if pd.isna(aired):\n",
        "        return np.nan\n",
        "    try:\n",
        "        start_year = int(str(aired).split()[2])\n",
        "        return start_year\n",
        "    except (AttributeError, ValueError, IndexError):\n",
        "        return np.nan\n",
        "\n",
        "# Apply the function to create a new 'start_year' column\n",
        "df['start_year'] = df.apply(preprocess_aired, axis=1)\n",
        "\n",
        "\n",
        "# Handle missing values in numerical columns\n",
        "\n",
        "numeric_columns = ['episodes', 'members', 'popularity', 'ranked', 'score']\n",
        "for column in numeric_columns:\n",
        "    # Convert numeric values to float, and non-numeric values to NaN\n",
        "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
        "\n",
        "# Impute missing values using mean strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])"
      ],
      "metadata": {
        "id": "lMfZkZQdAW04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine relevant text features for TF-IDF\n",
        "df['features'] = df['synopsis'] + ' ' + df['genre'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "sD9iOyv73Su4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TF-IDF to create feature vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english',max_features=None)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['features'])"
      ],
      "metadata": {
        "id": "MakBhy2F3YyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(tfidf_matrix, 'tfidf_matrix.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfOo3tSebTVz",
        "outputId": "249f55a1-72a9-4d27-edb0-2597f56448dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_matrix.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix_np = tfidf_matrix.toarray().astype(np.float32)"
      ],
      "metadata": {
        "id": "fsj4CLfefiGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
        "knn_model.fit(tfidf_matrix_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2KgUvT62Z0Rq",
        "outputId": "2164e069-0b2a-4fbc-a519-6cc99824fe1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=10)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hybrid_recommendations(user_id, anime_title, top_n=10):\n",
        "    anime_index = df[df['title'] == anime_title].index\n",
        "    if len(anime_index) == 0:\n",
        "        return [], []  # Anime not found\n",
        "\n",
        "    collaborative_filtering_indices = get_collaborative_filtering_recommendations(anime_index)\n",
        "\n",
        "    # Exclude the queried anime itself from collaborative filtering recommendations\n",
        "    collaborative_filtering_indices = collaborative_filtering_indices[1:]\n",
        "\n",
        "    # Extract titles of collaborative filtering recommendations\n",
        "    collaborative_filtering_recommendations = df.iloc[collaborative_filtering_indices]['title'].tolist()\n",
        "\n",
        "    return collaborative_filtering_recommendations[:top_n]\n",
        "\n"
      ],
      "metadata": {
        "id": "OsOGsAuR3mjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_collaborative_filtering_recommendations(anime_index):\n",
        "    distances, indices = knn_model.kneighbors(tfidf_matrix_np[anime_index], n_neighbors=10)\n",
        "    return indices.flatten()"
      ],
      "metadata": {
        "id": "JARb2D3gDd-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 5530  # Replace with the actual user ID\n",
        "anime_title = 'Pandora Hearts'  # Replace with the actual anime title\n",
        "collaborative_filtering_recs = get_hybrid_recommendations(user_id, anime_title)\n",
        "print(\"Collaborative Filtering Recommendations:\", collaborative_filtering_recs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BQHtsp83uJJ",
        "outputId": "9128d5b9-9554-43ff-d90a-48c46fa9402a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collaborative Filtering Recommendations: ['Oz no Mahoutsukai (1986)', 'OZ', 'Oz no Mahoutsukai', 'Made in Abyss', 'Oz no Mahoutsukai no Koutsuu Anzen no Tabi', 'Space Oz no Bouken', 'Code Geass: Soubou no Oz Picture Drama', 'Summer Wars', 'Zhandou Wang Zhi Jufeng Zhan Hun']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_count = sum(1 for row in df)\n",
        "\n",
        "print(f'Number of rows in : {row_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD4Dg-N6mPzm",
        "outputId": "4808e051-570b-41d1-eaa4-8feb109678e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in : 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gpALKctAFGTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('knn_model.pkl', 'wb') as f:\n",
        "    pickle.dump(knn_model, f)"
      ],
      "metadata": {
        "id": "KvPCTJDUTByo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model_path = 'collaborative_filtering_model.h5'\n",
        "tf.keras.models.save_model(knn_model, knn_model_path, save_format='h5')\n",
        "\n",
        "# Example usage to load the models\n",
        "loaded_tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "loaded_knn_model = tf.keras.models.load_model(knn_model_path)"
      ],
      "metadata": {
        "id": "udCOgKxmNigP",
        "outputId": "681fd410-bf0f-4f53-f6d0-0eb00daa5e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-009eafab9eda>:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(knn_model, knn_model_path, save_format='h5')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NearestNeighbors' object has no attribute 'outputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-009eafab9eda>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'collaborative_filtering_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Example usage to load the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloaded_tfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf_vectorizer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Legacy case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         return legacy_sm_saving_lib.save_model(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/saving_utils.py\u001b[0m in \u001b[0;36mtry_build_compiled_arguments\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    349\u001b[0m     if (\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_v1_layer_or_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     ):\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NearestNeighbors' object has no attribute 'outputs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF-IDF vectorizer from joblib\n",
        "loaded_tfidf_vectorizer = joblib.load('tfidf_vectorizer.joblib')\n",
        "\n",
        "# Function to convert the TF-IDF transform to NumPy array\n",
        "def tfidf_transform(x):\n",
        "    return loaded_tfidf_vectorizer.transform(x).toarray().astype(np.float32)"
      ],
      "metadata": {
        "id": "xCr9TDbGTEZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom layer for TF-IDF transformation\n",
        "class TfidfLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, tfidf_model, **kwargs):\n",
        "        self.tfidf_model = tfidf_model\n",
        "        super(TfidfLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        return tf.py_function(tfidf_transform, [x], Tout=tf.float32)\n",
        "\n",
        "def transform_with_numpy(x):\n",
        "    return np.asarray(loaded_tfidf_vectorizer.transform(x).toarray(), dtype=np.float32)"
      ],
      "metadata": {
        "id": "lFpe7YY0TICn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eager_pyfunc_conversion(x):\n",
        "    return tf.py_function(transform_with_numpy, [x], tf.float32)"
      ],
      "metadata": {
        "id": "D7KYfZI7Udnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=1000, output_mode=\"tf-idf\")\n",
        "text_vectorizer.adapt(df['features'].values)"
      ],
      "metadata": {
        "id": "5s07oAcfgrK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Sequential API with a combination of layers for the custom operation\n",
        "model_tfidf = tf.keras.Sequential([\n",
        "    Input(shape=(1,), dtype=tf.string),\n",
        "    text_vectorizer\n",
        "])"
      ],
      "metadata": {
        "id": "1XVm6AP6TSDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model if needed\n",
        "#model_tfidf.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_tfidf.save(\"saved_model_tfidf\")"
      ],
      "metadata": {
        "id": "K_QQSm9rTZrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_custom_op(interpreter):\n",
        "    def my_custom_op_impl(inputs, outputs):\n",
        "        # Implement your custom op logic here\n",
        "        pass\n",
        "    interpreter.add_custom_op(tf.lite.OpDef(name=\"MyCustomOp\", opcode=1, custom_code=my_custom_op_impl))"
      ],
      "metadata": {
        "id": "ZE0KjbxPX8BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model back\n",
        "loaded_model = tf.keras.models.load_model(\"saved_model_tfidf\")\n",
        "\n",
        "# Replace custom op with Lambda layer\n",
        "loaded_model.layers[-1] = Lambda(lambda x: tfidf_vectorizer.transform(x.numpy()).astype(np.float32))\n",
        "\n",
        "\n",
        "# Create a concrete function from the SavedModel\n",
        "concrete_func = loaded_model.signatures[\n",
        "    tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]"
      ],
      "metadata": {
        "id": "UYMADY_Cfbbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Keras model to a TensorFlow Lite model.\n",
        "converter_tflite = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "\n",
        "# Add the missing input tensor to the input_tensors list.\n",
        "converter_tflite.input_tensors = [tf.TensorSpec(shape=(None,), dtype=tf.float32, name=\"sequential_1/text_vectorization/string_lookup_2/None_Lookup/LookupTableFindV2/table_handle\")]\n",
        "\n",
        "# Convert the Keras model to a TensorFlow Lite model.\n",
        "tflite_model_tfidf = converter_tflite.convert()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mlbt8OdMTfBx",
        "outputId": "5bf6abef-3597-4d59-ff90-af2b54d55ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "Could not translate MLIR to FlatBuffer. UNKNOWN: /usr/lib/python3.10/runpy.py:196:1: error: 'tf.StringLower' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.StaticRegexReplace' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.StringSplitV2' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.DenseBincount' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.RaggedBincount' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: DenseBincount, RaggedBincount, StaticRegexReplace, StringLower, StringSplitV2\nDetails:\n\ttf.DenseBincount(tensor<?xi32>, tensor<i32>, tensor<0xi64>) -> (tensor<?xi64>) : {T = i64, Tidx = i32, binary_output = false, device = \"\"}\n\ttf.RaggedBincount(tensor<?xi64>, tensor<*xi64>, tensor<*xi64>, tensor<0xf32>) -> (tensor<*xf32>) : {T = f32, Tidx = i64, binary_output = false, device = \"\"}\n\ttf.StaticRegexReplace(tensor<?x1x!tf_type.string>) -> (tensor<?x1x!tf_type.string>) : {device = \"\", pattern = \"[!\\22#$%&()\\\\*\\\\+,-\\\\./:;<=>?@\\\\[\\\\\\\\\\\\]^_`{|}~\\\\']\", replace_global = true, rewrite = \"\"}\n\ttf.StringLower(tensor<?x1x!tf_type.string>) -> (tensor<?x1x!tf_type.string>) : {device = \"\", encoding = \"\"}\n\ttf.StringSplitV2(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x2xi64>, tensor<?x!tf_type.string>, tensor<2xi64>) : {device = \"\", maxsplit = -1 : i64}\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8824143a7e62>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert the Keras model to a TensorFlow Lite model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtflite_model_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter_tflite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \"\"\"\n\u001b[0;32m-> 1601\u001b[0;31m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1580\u001b[0m       )\n\u001b[1;32m   1581\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         return super(TFLiteKerasModelConverterV2, self).convert(\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;31m# Converts model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m     result = _convert_graphdef(\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_graphdef\u001b[0;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    364\u001b[0m               \u001b[0menable_mlir_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           )\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m   return _run_deprecated_conversion_binary(\n",
            "\u001b[0;31mConverterError\u001b[0m: Could not translate MLIR to FlatBuffer. UNKNOWN: /usr/lib/python3.10/runpy.py:196:1: error: 'tf.StringLower' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.StaticRegexReplace' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.StringSplitV2' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.DenseBincount' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n/usr/lib/python3.10/runpy.py:196:1: error: 'tf.RaggedBincount' op is neither a custom op nor a flex op\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_3\"]): called from\n/usr/lib/python3.10/runpy.py:196:1: note: Error code: ERROR_NEEDS_FLEX_OPS\n    return _run_code(code, main_globals, None,\n^\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: DenseBincount, RaggedBincount, StaticRegexReplace, StringLower, StringSplitV2\nDetails:\n\ttf.DenseBincount(tensor<?xi32>, tensor<i32>, tensor<0xi64>) -> (tensor<?xi64>) : {T = i64, Tidx = i32, binary_output = false, device = \"\"}\n\ttf.RaggedBincount(tensor<?xi64>, tensor<*xi64>, tensor<*xi64>, tensor<0xf32>) -> (tensor<*xf32>) : {T = f32, Tidx = i64, binary_output = false, device = \"\"}\n\ttf.StaticRegexReplace(tensor<?x1x!tf_type.string>) -> (tensor<?x1x!tf_type.string>) : {device = \"\", pattern = \"[!\\22#$%&()\\\\*\\\\+,-\\\\./:;<=>?@\\\\[\\\\\\\\\\\\]^_`{|}~\\\\']\", replace_global = true, rewrite = \"\"}\n\ttf.StringLower(tensor<?x1x!tf_type.string>) -> (tensor<?x1x!tf_type.string>) : {device = \"\", encoding = \"\"}\n\ttf.StringSplitV2(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x2xi64>, tensor<?x!tf_type.string>, tensor<2xi64>) : {device = \"\", maxsplit = -1 : i64}\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert collaborative filtering model to TFLite model\n",
        "with open('knn_model.pkl', 'rb') as f:\n",
        "    knn_model = pickle.load(f)\n",
        "\n",
        "converter_collab = tf.lite.TFLiteConverter.from_keras_model(knn_model)\n",
        "tflite_model_collab = converter_collab.convert()\n",
        "\n",
        "# Save the TFLite models\n",
        "with open('tfidf_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model_tfidf)\n",
        "\n",
        "with open('collab_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model_collab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "w1Jd04iLal3w",
        "outputId": "b43376f8-a801-446e-d40f-bbeb945317a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "Could not translate MLIR to FlatBuffer. UNKNOWN: <unknown>:0: error: loc(callsite(callsite(fused[\"EagerPyFunc:\", \"sequential_3/lambda_3/EagerPyFunc@__inference__wrapped_model_710\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_758\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): 'tf.EagerPyFunc' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"EagerPyFunc:\", \"sequential_3/lambda_3/EagerPyFunc@__inference__wrapped_model_710\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_758\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): Error code: ERROR_NEEDS_CUSTOM_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom \nCustom ops: EagerPyFunc\nDetails:\n\ttf.EagerPyFunc(tensor<?x1x!tf_type.string>) -> (tensor<*xf32>) : {Tin = [!tf_type.string], Tout = [f32], device = \"/job:localhost/replica:0/task:0/device:CPU:0\", is_async = false, token = \"pyfunc_13\"}\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2b51e35c362f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convert the SavedModel to TFLite model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mconverter_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved_model_tfidf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtflite_model_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m       )\n\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconverter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m     return self._optimize_tflite_model(\n\u001b[1;32m   1333\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_io\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_new_quantizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_saved_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    999\u001b[0m   \u001b[0mmodel_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m   \u001b[0mconversion_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_conversion_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m   1002\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    364\u001b[0m               \u001b[0menable_mlir_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           )\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m   return _run_deprecated_conversion_binary(\n",
            "\u001b[0;31mConverterError\u001b[0m: Could not translate MLIR to FlatBuffer. UNKNOWN: <unknown>:0: error: loc(callsite(callsite(fused[\"EagerPyFunc:\", \"sequential_3/lambda_3/EagerPyFunc@__inference__wrapped_model_710\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_758\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): 'tf.EagerPyFunc' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"EagerPyFunc:\", \"sequential_3/lambda_3/EagerPyFunc@__inference__wrapped_model_710\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_758\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall\"])): Error code: ERROR_NEEDS_CUSTOM_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom \nCustom ops: EagerPyFunc\nDetails:\n\ttf.EagerPyFunc(tensor<?x1x!tf_type.string>) -> (tensor<*xf32>) : {Tin = [!tf_type.string], Tout = [f32], device = \"/job:localhost/replica:0/task:0/device:CPU:0\", is_async = false, token = \"pyfunc_13\"}\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates(['uid', 'title'], keep='first')\n"
      ],
      "metadata": {
        "id": "NjUbpbPb7V1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}